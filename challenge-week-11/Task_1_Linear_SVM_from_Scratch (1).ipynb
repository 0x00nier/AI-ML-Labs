{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U_tcuiFmIToA"
   },
   "source": [
    "#Support vector machine-based software reuse prediction\n",
    "\n",
    "## Objective: To implement SVM from scratch and also compared it with using sklearn's SVM\n",
    "\n",
    "Source of SVM: https://dzone.com/articles/classification-from-scratch-svm-78\n",
    "\n",
    "In machine learning, support-vector machines (SVMs, also support-vector networks) are supervised learning models with associated learning algorithms that analyze data used for classification and regression analysis. SVM presents one of the most robust prediction methods, based on the statistical learning framework. Given a set of training examples, each marked as belonging to one or the other of two categories, an SVM training algorithm builds a model that assigns new examples to one category or the other, making it a non-probabilistic binary linear classifier (although methods such as Platt scaling exist to use SVM in a probabilistic classification setting). An SVM model is a representation of the examples as points in space, mapped so that the examples of the separate categories are divided by a clear gap that is as wide as possible. New examples are then mapped into that same space and predicted to belong to a category based on the side of the gap on which they fall.\n",
    "\n",
    "In addition to performing linear classification, SVMs can efficiently perform a non-linear classification using what is called the kernel trick, implicitly mapping their inputs into high-dimensional feature spaces.\n",
    "\n",
    "\n",
    "### 1. For all ti in training set:\n",
    " ti.w + b <= -1   if yi = -1 \n",
    "\n",
    " ti.w + b >= +1 if yi = +1 \n",
    "\n",
    "or\n",
    "\n",
    "yi(ti.w+b) >= 1\n",
    "\n",
    "###2. for all support vectors (i.e., data points that defines margin)\n",
    "  ti.w+b = -1    where ti is -ve support vector and yi is -1\n",
    "\n",
    "  ti.w+b = +1    where ti is +ve support vector and yi is +1\n",
    "\n",
    "###3. For decision Boundary i.e., yi(ti.w+b)=0 where ti lies within decision boundary\n",
    "### 4. The goal is to maximize width (W) or to minimize |w|\n",
    "\n",
    "W = ((X+ - X-).w)/|w|\n",
    "\n",
    "### 5. After obtaining the tuned w and b we have\n",
    "\n",
    "x.w+b = 1 is line passing through +ve support vectors\n",
    "\n",
    "x.w+b = -1 is line passing through -ve support vectors\n",
    "\n",
    "x.w+b = 0 is decision boundary\n",
    "\n",
    "### 6. As you know it is not possible that the support vector lines always pass through support vectors\n",
    "\n",
    "### 7. Thus, it is a convex optimization issue and will lead to a global minimum\n",
    "\n",
    "### 8. This is Linear SVM i.e., kernel is linear\n",
    "\n",
    "#Dataset: Reuse/predicting successful reuse\n",
    "\n",
    "# Attribute Information:\n",
    "1.  Project ID {A,B,D,E,F,G,H,I,J,K,L,M,N,O,P,Q,R,S,T,U,V,W,X,Y}\n",
    "2.  Software Staff {L,M,S}\n",
    "3.  Overall Staff {L,X,M,S}\n",
    "4.  Type of Software Production {product-family,isolated}\n",
    "5.  Software and Product {product,alone,process,NA}\n",
    "6.  SP maturity {high,middle,low}\n",
    "7.  Application Domain {TLC,SE-Tools,Bank,Engine_Controller,FMS,ATC,TS,Space Manufacturing,Measurement,Finance,Book-Keeping}\n",
    "8.  Type of Software {Technical,Business,Embedded-RT,Non-Embedded-RT}\n",
    "9.  Size of Baseline {L,M,S,not_available}\n",
    "10. Development Approach {OO,proc,not_available}\n",
    "11. Staff Experience {high,middle,low,not_available}\n",
    "12. Top Management Commitment {yes,no}\n",
    "13. Key Reuse Roles Introduced {yes,no,NA}\n",
    "14. Reuse Processes Introduced {yes,no,NA}\n",
    "15. Non-Reuse Processes Modified {yes,no,NA}\n",
    "16. Repository {yes,NA}\n",
    "17. Human Factors {yes,no}\n",
    "18. Reuse Approach {tight,loose,NA}\n",
    "19. Work Products {D+C,C,R+D+C,NA}\n",
    "20. Domain Analysis {yes,no,NA}\n",
    "21. Origin {ex-novo,as-is,reeng,NA}\n",
    "22. Independent Team {yes,no,NA}\n",
    "23. When Assests Developed {before,justintime,NA}\n",
    "24. Qualification {yes,no,NA}\n",
    "25. Configuration Management {yes,no,NA}\n",
    "26. Rewards Policy {no,yes}\n",
    "27. Assests {51_to_100,21_to_50,100+,1_to_20,NA}\n",
    "\n",
    "#Target classes \n",
    "Success or Failure {success,failure}\n",
    "\n",
    "#Source: http://promise.site.uottawa.ca/SERepository/datasets/reuse.arff\n",
    "\n",
    "#Tasks:\n",
    "1. Initially, load arff dataset\n",
    "2. Apply pre-processing techniques\n",
    "3. Divide data into training and testing sets.\n",
    "4. Build SVM model from scratch\n",
    "5. Test your own SVM model\n",
    "6. Obtain precision and recall\n",
    "7. Implement sklearn's model on processed data\n",
    "8. Compare your SVM model with sklearn's model\n",
    "\n",
    "##Task 1: Implement linear SVM from scratch  \n",
    "# Algorithm of Linear SVM\n",
    "1.  Initialize with random big value of w say(w0,w0) we will decrease it later\n",
    "2.  Set step size as w0*0.1\n",
    "3.  A minimum value of b, may increase it during the process\n",
    "\n",
    "        i.  b will range from (-b0 < b < +b0, step = step*b_multiple)\n",
    "\n",
    "        ii. It is also computational extensive. Therefore, define b0 wisely\n",
    "4.  Check for points ti in dataset:\n",
    "\n",
    "        i.  Check all transformation of w like (w0,w0), (-w0,w0), (w0,-w0), (-w0,-w0)\n",
    "\n",
    "        ii. if not yi(ti.w+b)>=1 for all points then break\n",
    "\n",
    "        iii.  Else evaluate |w| and put it in dictionary as key and (w,b) as values\n",
    "5.  If w<=0 then current step is completed and move to step 6\n",
    "\n",
    "        Else minimize w as (w0-step,w0-step) and move to step 3\n",
    "6.  While step not becomes w0*0.001 \n",
    "\n",
    "        i.  step = step*0.1\n",
    "\n",
    "        ii. move to step 3\n",
    "\n",
    "7.  Select (w,b) that contain minimum |w| form the dictionary\n",
    "\n",
    "##Task 2: Implement sklearn's SVM\n",
    "\n",
    "##Task 3: Compare your SVM with sklearn's SVM with concluding remarks\n",
    "\n",
    "#Helping links:\n",
    "\n",
    "https://pythonprogramming.net/svm-in-python-machine-learning-tutorial/\n",
    "\n",
    "https://medium.com/deep-math-machine-learning-ai/chapter-3-1-svm-from-scratch-in-python-86f93f853dc\n",
    "\n",
    "https://stackabuse.com/implementing-svm-and-kernel-svm-with-pythons-scikit-learn/\n",
    "\n",
    "http://ecomunsing.com/build-your-own-support-vector-machine\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1yGvcerZa0S8"
   },
   "source": [
    "## Task 1: Implement linear SVM from scratch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T14:09:09.052297Z",
     "start_time": "2020-10-20T14:09:09.036843Z"
    },
    "id": "Duh_Q74qIidS"
   },
   "outputs": [],
   "source": [
    "# Load the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import MinMaxScaler,LabelEncoder\n",
    "from scipy.io import arff\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score,recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T13:57:46.428911Z",
     "start_time": "2020-10-20T13:57:46.260056Z"
    },
    "id": "SyioH2iYIjhk"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Project ID</th>\n",
       "      <th>Software Staff</th>\n",
       "      <th>Overall Staff</th>\n",
       "      <th>Type of Software Production</th>\n",
       "      <th>Software and Product</th>\n",
       "      <th>SP maturity</th>\n",
       "      <th>Application Domain</th>\n",
       "      <th>Type of Software</th>\n",
       "      <th>Size of Baseline</th>\n",
       "      <th>Development Approach</th>\n",
       "      <th>...</th>\n",
       "      <th>Work Products</th>\n",
       "      <th>Domain Analysis</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Independent Team</th>\n",
       "      <th>When Assests Developed</th>\n",
       "      <th>Qualification</th>\n",
       "      <th>Configuration Management</th>\n",
       "      <th>Rewards Policy</th>\n",
       "      <th># assests</th>\n",
       "      <th>Success or Failure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>L</td>\n",
       "      <td>L</td>\n",
       "      <td>product-family</td>\n",
       "      <td>product</td>\n",
       "      <td>high</td>\n",
       "      <td>TLC</td>\n",
       "      <td>Technical</td>\n",
       "      <td>L</td>\n",
       "      <td>OO</td>\n",
       "      <td>...</td>\n",
       "      <td>D+C</td>\n",
       "      <td>yes</td>\n",
       "      <td>ex-novo</td>\n",
       "      <td>yes</td>\n",
       "      <td>before</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>51_to_100</td>\n",
       "      <td>success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>L</td>\n",
       "      <td>L</td>\n",
       "      <td>product-family</td>\n",
       "      <td>product</td>\n",
       "      <td>high</td>\n",
       "      <td>TLC</td>\n",
       "      <td>Technical</td>\n",
       "      <td>M</td>\n",
       "      <td>OO</td>\n",
       "      <td>...</td>\n",
       "      <td>D+C</td>\n",
       "      <td>yes</td>\n",
       "      <td>ex-novo</td>\n",
       "      <td>yes</td>\n",
       "      <td>before</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>51_to_100</td>\n",
       "      <td>success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D</td>\n",
       "      <td>L</td>\n",
       "      <td>L</td>\n",
       "      <td>isolated</td>\n",
       "      <td>alone</td>\n",
       "      <td>middle</td>\n",
       "      <td>SE-Tools</td>\n",
       "      <td>Technical</td>\n",
       "      <td>M</td>\n",
       "      <td>OO</td>\n",
       "      <td>...</td>\n",
       "      <td>C</td>\n",
       "      <td>no</td>\n",
       "      <td>as-is</td>\n",
       "      <td>no</td>\n",
       "      <td>before</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>21_to_50</td>\n",
       "      <td>failure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E</td>\n",
       "      <td>L</td>\n",
       "      <td>L</td>\n",
       "      <td>isolated</td>\n",
       "      <td>alone</td>\n",
       "      <td>middle</td>\n",
       "      <td>TLC</td>\n",
       "      <td>Technical</td>\n",
       "      <td>M</td>\n",
       "      <td>OO</td>\n",
       "      <td>...</td>\n",
       "      <td>C</td>\n",
       "      <td>no</td>\n",
       "      <td>as-is</td>\n",
       "      <td>no</td>\n",
       "      <td>before</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>21_to_50</td>\n",
       "      <td>failure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F</td>\n",
       "      <td>L</td>\n",
       "      <td>L</td>\n",
       "      <td>isolated</td>\n",
       "      <td>alone</td>\n",
       "      <td>middle</td>\n",
       "      <td>TLC</td>\n",
       "      <td>Technical</td>\n",
       "      <td>M</td>\n",
       "      <td>OO</td>\n",
       "      <td>...</td>\n",
       "      <td>C</td>\n",
       "      <td>no</td>\n",
       "      <td>as-is</td>\n",
       "      <td>no</td>\n",
       "      <td>before</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>21_to_50</td>\n",
       "      <td>failure</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Project ID Software Staff Overall Staff Type of Software Production  \\\n",
       "0          A              L             L              product-family   \n",
       "1          B              L             L              product-family   \n",
       "2          D              L             L                    isolated   \n",
       "3          E              L             L                    isolated   \n",
       "4          F              L             L                    isolated   \n",
       "\n",
       "  Software and Product SP maturity Application Domain Type of Software  \\\n",
       "0              product        high                TLC        Technical   \n",
       "1              product        high                TLC        Technical   \n",
       "2                alone      middle           SE-Tools        Technical   \n",
       "3                alone      middle                TLC        Technical   \n",
       "4                alone      middle                TLC        Technical   \n",
       "\n",
       "  Size of Baseline Development Approach  ... Work Products Domain Analysis  \\\n",
       "0                L                   OO  ...           D+C             yes   \n",
       "1                M                   OO  ...           D+C             yes   \n",
       "2                M                   OO  ...             C              no   \n",
       "3                M                   OO  ...             C              no   \n",
       "4                M                   OO  ...             C              no   \n",
       "\n",
       "    Origin Independent Team When Assests Developed Qualification  \\\n",
       "0  ex-novo              yes                 before           yes   \n",
       "1  ex-novo              yes                 before           yes   \n",
       "2    as-is               no                 before            no   \n",
       "3    as-is               no                 before            no   \n",
       "4    as-is               no                 before            no   \n",
       "\n",
       "  Configuration Management Rewards Policy  # assests Success or Failure  \n",
       "0                      yes             no  51_to_100            success  \n",
       "1                      yes             no  51_to_100            success  \n",
       "2                       no            yes   21_to_50            failure  \n",
       "3                       no            yes   21_to_50            failure  \n",
       "4                       no            yes   21_to_50            failure  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the arff dataset \n",
    "# Shuffel the dataset\n",
    "data = arff.loadarff('reuse.arff')\n",
    "df=pd.DataFrame(data[0])\n",
    "for i in range(24):\n",
    "    for j in range(28):\n",
    "        df.iloc[i,j]=df.iloc[i,j].decode(\"utf-8\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T13:57:47.403611Z",
     "start_time": "2020-10-20T13:57:47.387991Z"
    }
   },
   "outputs": [],
   "source": [
    "df.drop(index=22,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T13:57:47.808070Z",
     "start_time": "2020-10-20T13:57:47.745758Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Project ID</th>\n",
       "      <th>Software Staff</th>\n",
       "      <th>Overall Staff</th>\n",
       "      <th>Type of Software Production</th>\n",
       "      <th>Software and Product</th>\n",
       "      <th>SP maturity</th>\n",
       "      <th>Application Domain</th>\n",
       "      <th>Type of Software</th>\n",
       "      <th>Size of Baseline</th>\n",
       "      <th>Development Approach</th>\n",
       "      <th>...</th>\n",
       "      <th>Work Products</th>\n",
       "      <th>Domain Analysis</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Independent Team</th>\n",
       "      <th>When Assests Developed</th>\n",
       "      <th>Qualification</th>\n",
       "      <th>Configuration Management</th>\n",
       "      <th>Rewards Policy</th>\n",
       "      <th># assests</th>\n",
       "      <th>Success or Failure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Project ID  Software Staff  Overall Staff  Type of Software Production  \\\n",
       "0           0               0              0                            1   \n",
       "1           1               0              0                            1   \n",
       "2           2               0              0                            0   \n",
       "3           3               0              0                            0   \n",
       "4           4               0              0                            0   \n",
       "\n",
       "   Software and Product  SP maturity  Application Domain  Type of Software  \\\n",
       "0                     2            0                   9                 3   \n",
       "1                     2            0                   9                 3   \n",
       "2                     0            2                   7                 3   \n",
       "3                     0            2                   9                 3   \n",
       "4                     0            2                   9                 3   \n",
       "\n",
       "   Size of Baseline  Development Approach  ...  Work Products  \\\n",
       "0                 0                     0  ...              1   \n",
       "1                 1                     0  ...              1   \n",
       "2                 1                     0  ...              0   \n",
       "3                 1                     0  ...              0   \n",
       "4                 1                     0  ...              0   \n",
       "\n",
       "   Domain Analysis  Origin  Independent Team  When Assests Developed  \\\n",
       "0                1       1                 1                       0   \n",
       "1                1       1                 1                       0   \n",
       "2                0       0                 0                       0   \n",
       "3                0       0                 0                       0   \n",
       "4                0       0                 0                       0   \n",
       "\n",
       "   Qualification  Configuration Management  Rewards Policy  # assests  \\\n",
       "0              1                         1               0          3   \n",
       "1              1                         1               0          3   \n",
       "2              0                         0               1          2   \n",
       "3              0                         0               1          2   \n",
       "4              0                         0               1          2   \n",
       "\n",
       "   Success or Failure  \n",
       "0                   1  \n",
       "1                   1  \n",
       "2                   0  \n",
       "3                   0  \n",
       "4                   0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc=LabelEncoder()\n",
    "for i in df.columns:\n",
    "    df[i]=enc.fit_transform(df[i])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T13:57:48.946487Z",
     "start_time": "2020-10-20T13:57:48.930893Z"
    },
    "id": "vtfupr9JInhf"
   },
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "# Encoding categorical variables (if any)\n",
    "# Feature Scaling\n",
    "# Filling missing values (if any)\n",
    "X=df.drop(columns='Success or Failure')\n",
    "y=df['Success or Failure']\n",
    "X.insert(loc=len(X.columns),column='intercept',value=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T13:57:49.609788Z",
     "start_time": "2020-10-20T13:57:49.578676Z"
    },
    "id": "13owZH7mIpZp"
   },
   "outputs": [],
   "source": [
    "# Divide the dataset to training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y , test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T14:20:02.449579Z",
     "start_time": "2020-10-20T14:20:02.418296Z"
    },
    "id": "-KEJ1BB8a5xQ"
   },
   "outputs": [],
   "source": [
    "reg_strength = 0\n",
    "learning_rate = 0.000001\n",
    "def compute_cost(W, X, Y):\n",
    "    N = X.shape[0]\n",
    "    distances = 1 - Y * (np.dot(X, W))\n",
    "    distances[distances < 0] = 0 \n",
    "    hinge_loss = regularization_strength * (np.sum(distances) / N)\n",
    "    cost = 1 / 2 * np.dot(W, W) + hinge_loss\n",
    "    return cost\n",
    "def calculate_cost_gradient(W, X_batch, Y_batch):\n",
    "    if type(Y_batch) == np.float64:\n",
    "        Y_batch = np.array([Y_batch])\n",
    "        X_batch = np.array([X_batch])  \n",
    "    distance = 1 - (Y_batch * np.dot(X_batch, W))\n",
    "    dw = np.zeros(len(W))\n",
    "    for ind,d in enumerate(distance):\n",
    "        if max(0, d) == 0:\n",
    "            di = W\n",
    "        else:\n",
    "            di = W - (regularization_strength * Y_batch[ind] * X_batch[ind])\n",
    "        dw += di\n",
    "\n",
    "    dw = dw/len(Y_batch)  \n",
    "    return dw\n",
    "\n",
    "def sgd(features, outputs):\n",
    "    max_epochs = 5000\n",
    "    weights = np.zeros(features.shape[1])\n",
    "    nth = 0\n",
    "    prev_cost = float(\"inf\")\n",
    "    cost_threshold = 0.01  \n",
    "    for epoch in range(1, max_epochs):\n",
    "        X, Y = shuffle(features, outputs)\n",
    "        ascent = calculate_cost_gradient(weights, X, Y)\n",
    "        weights = weights - (learning_rate * ascent)\n",
    "        if epoch == 2 ** nth or epoch == max_epochs - 1:\n",
    "            cost = compute_cost(weights, features, outputs)\n",
    "            print(\"Epoch is: {} and Cost is: {}\".format(epoch, cost))\n",
    "            #if abs(prev_cost - cost) < cost_threshold * prev_cost:\n",
    "            #    return weights\n",
    "            #prev_cost = cost\n",
    "            #nth += 1\n",
    "    return weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T14:20:04.269222Z",
     "start_time": "2020-10-20T14:20:03.494465Z"
    },
    "id": "jOIhehoYbSsJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch is: 1 and Cost is: 4833.207039648439\n",
      "Epoch is: 4999 and Cost is: 4375.0096087674765\n"
     ]
    }
   ],
   "source": [
    "# Train and test your SVM models\n",
    "W = sgd(X_train.to_numpy(), y_train.to_numpy())\n",
    "y_train_predicted = np.array([])\n",
    "for i in range(X_train.shape[0]):\n",
    "    yp = np.sign(np.dot(W, X_train.to_numpy()[i])) \n",
    "    y_train_predicted = np.append(y_train_predicted, yp)\n",
    "y_test_predicted = np.array([])\n",
    "for i in range(X_test.shape[0]):\n",
    "    yp = np.sign(np.dot(W, X_test.to_numpy()[i])) \n",
    "    y_test_predicted = np.append(y_test_predicted, yp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T14:20:08.016647Z",
     "start_time": "2020-10-20T14:20:07.979048Z"
    },
    "id": "XUBOrqrbbX-u"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on train dataset: 0.5625\n",
      "recall on train dataset: 1.0\n",
      "precision on train dataset: 1.0\n",
      "\n",
      "accuracy on test dataset: 0.8571428571428571\n",
      "recall on test dataset: 1.0\n",
      "precision on test dataset: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Evaluate training and testing precision and recall\n",
    "print(\"accuracy on train dataset: {}\".format(accuracy_score(y_train.to_numpy(), y_train_predicted)))\n",
    "print(\"recall on train dataset: {}\".format(recall_score(y_train, y_train_predicted)))\n",
    "print(\"precision on train dataset: {}\".format(recall_score(y_train, y_train_predicted)))\n",
    "print()\n",
    "print(\"accuracy on test dataset: {}\".format(accuracy_score(y_test.to_numpy(), y_test_predicted)))\n",
    "print(\"recall on test dataset: {}\".format(recall_score(y_test, y_test_predicted)))\n",
    "print(\"precision on test dataset: {}\".format(recall_score(y_test, y_test_predicted)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9hZF7xcjbdAF"
   },
   "source": [
    "##Task 2: Implement sklearn's SVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T14:10:11.262980Z",
     "start_time": "2020-10-20T14:10:11.247369Z"
    },
    "id": "1DSX6JMEbfss"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 28)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the preprocessed dataset here\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2yqNwnVCbkxG"
   },
   "outputs": [],
   "source": [
    "# Divide the dataset to training and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T14:12:14.118521Z",
     "start_time": "2020-10-20T14:12:14.102931Z"
    },
    "id": "eB_I4407bns6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained\n"
     ]
    }
   ],
   "source": [
    "# Train SVM model using sklearn's SVM\n",
    "\n",
    "model=SVC(kernel='linear')\n",
    "model.fit(X_train,y_train)\n",
    "y_train_predicted=model.predict(X_train)\n",
    "y_test_predicted=model.predict(X_test)\n",
    "print(\"Trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T14:12:23.483711Z",
     "start_time": "2020-10-20T14:12:23.440827Z"
    },
    "id": "GHOGKAXiCsSN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on train dataset: 1.0\n",
      "recall on train dataset: 1.0\n",
      "precision on train dataset: 1.0\n",
      "\n",
      "accuracy on test dataset: 1.0\n",
      "recall on test dataset: 1.0\n",
      "precision on test dataset: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Evaluate training and testing precision and recall\n",
    "print(\"accuracy on train dataset: {}\".format(accuracy_score(y_train.to_numpy(), y_train_predicted)))\n",
    "print(\"recall on train dataset: {}\".format(recall_score(y_train, y_train_predicted)))\n",
    "print(\"precision on train dataset: {}\".format(recall_score(y_train, y_train_predicted)))\n",
    "print()\n",
    "print(\"accuracy on test dataset: {}\".format(accuracy_score(y_test.to_numpy(), y_test_predicted)))\n",
    "print(\"recall on test dataset: {}\".format(recall_score(y_test, y_test_predicted)))\n",
    "print(\"precision on test dataset: {}\".format(recall_score(y_test, y_test_predicted)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aK086juobpRo"
   },
   "outputs": [],
   "source": [
    "# Play with the intial/hyper parameters of the models(Optional)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EPw_-SMyrka_"
   },
   "source": [
    "\n",
    "##Task 3: Compare your SVM with sklearn's SVM with concluding remarks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual Implementation\n",
    "In the manually implemented Linear SVM Classifier, there was a huge difference between training and testing accuracy. I believe this is mostly due to the lack of enough data and the manually implemented classifier to be lacking in its polynomial aspects per se and therefore isn't able to plot the best decision boundary possible. Since it does better on the testing set, this would mean, that the boundary produced worked with data that was easily seperable. The confidence of scores in terms of recall and precision suggests that the positive examples were easily filtered but we do not see the same for negative examples. So our model needs to filter the negative examples way better to increasing training accuracy. My guess is that the test split therefore had more amount of positive examples than negative examples, therefore the sheer amount of difference in results\n",
    "\n",
    "# Sklearn Implementation\n",
    "The sklearn implementation on a Linear kernel with default hyperparameters does very well as compared to our earlier implementation. Any specific reasons for this difference of performance is not directly apparent but it is clear that the sklearn implementation was able to create a sufficiently good decision boundary to filter our the positive and negative examples simultaneously. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Task_1_Linear_SVM_from_Scratch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
